{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "####first we import all the  libraries that we are going to use \n",
    "#libraries for preproccesing and linar algebra\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "#libraries for deep learning :we are going to use FASTAI as a framework on top of pytorch \n",
    "import torch\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "#visualization library\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####phase1:IMPORTATION,EXPLORATORY DATA ANALYSIS AND PRE PROCESSING  \n",
    "traindf = pd.read_csv(\"train.csv\")\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking train dataset columns and data types\n",
    "traindf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some basic statistics on train dataset \n",
    "traindf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exloring the data \n",
    "classdata = (traindf.healthy + traindf.multiple_diseases+\n",
    "             traindf.rust + traindf.scab)\n",
    "classdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(classdata > 1)\n",
    "#---->this means that is problem is is not a multiclassification problem \n",
    "#since all examples falls under only one of the 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding .jpg to help us load images later on \n",
    "traindf[\"image_id\"] =traindf[\"image_id\"].astype(\"str\") + \".jpg\"\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now  lets define our classes to be:\n",
    "# 0 for healthy\n",
    "# 1 multiple_diseases\n",
    "# 2 rust\n",
    "# 3 scab\n",
    "traindf[\"label\"] = (0*traindf.healthy + 1*traindf.multiple_diseases+\n",
    "             2*traindf.rust + 3*traindf.scab)\n",
    "traindf.drop(columns=[\"healthy\",\"multiple_diseases\",\"rust\",\"scab\"],inplace=True)\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##some visual EDA to understand our data more \n",
    "#checking class unbalance\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "fig = go.Figure([go.Pie(labels=train_data.columns[1:],\n",
    "           values=train_data.iloc[:, 1:].sum().values)])\n",
    "fig.update_layout(title_text=\"Pie chart of targets\", template=\"simple_white\")\n",
    "fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.data[0].marker.line.width = 0.5\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of healthy class\n",
    "train_data[\"Healthy\"] = train_data[\"healthy\"].apply(bool).apply(str)\n",
    "fig = px.histogram(train_data, x=\"Healthy\", title=\"Healthy distribution\", color=\"Healthy\",\\\n",
    "            color_discrete_map={\n",
    "                \"True\": px.colors.qualitative.Plotly[0],\n",
    "                \"False\": px.colors.qualitative.Plotly[1]})\n",
    "fig.update_layout(template=\"simple_white\")\n",
    "fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.data[0].marker.line.width = 0.5\n",
    "fig.data[1].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.data[1].marker.line.width = 0.5\n",
    "fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scab class distribution \n",
    "train_data[\"Scab\"] = train_data[\"scab\"].apply(bool).apply(str)\n",
    "fig = px.histogram(train_data, x=\"Scab\", color=\"Scab\", title=\"Scab distribution\",\\\n",
    "            color_discrete_map={\n",
    "                \"True\": px.colors.qualitative.Plotly[1],\n",
    "                \"False\": px.colors.qualitative.Plotly[0]})\n",
    "fig.update_layout(template=\"simple_white\")\n",
    "fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.data[0].marker.line.width = 0.5\n",
    "fig.data[1].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.data[1].marker.line.width = 0.5\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rust distribution\n",
    "train_data[\"Rust\"] = train_data[\"rust\"].apply(bool).apply(str)\n",
    "fig = px.histogram(train_data, x=\"Rust\", color=\"Rust\", title=\"Rust distribution\",\\\n",
    "            color_discrete_map={\n",
    "                \"True\": px.colors.qualitative.Plotly[1],\n",
    "                \"False\": px.colors.qualitative.Plotly[0]})\n",
    "fig.update_layout(template=\"simple_white\")\n",
    "fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.data[0].marker.line.width = 0.5\n",
    "fig.data[1].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.data[1].marker.line.width = 0.5\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple deseases distribution\n",
    "train_data[\"Multiple diseases\"] = train_data[\"multiple_diseases\"].apply(bool).apply(str)\n",
    "fig = px.histogram(train_data, x=\"Multiple diseases\", color=\"Multiple diseases\", title=\"Multiple diseases distribution\",\\\n",
    "            color_discrete_map={\n",
    "                \"True\": px.colors.qualitative.Plotly[1],\n",
    "                \"False\": px.colors.qualitative.Plotly[0]})\n",
    "fig.update_layout(template=\"simple_white\")\n",
    "fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.data[0].marker.line.width = 0.5\n",
    "fig.data[1].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.data[1].marker.line.width = 0.5\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of transformation object this object help\n",
    "#augment our data by making transormations like flipping images and rotation...\n",
    "#since more data means better results ;) (usually)\n",
    "transformations = get_transforms(do_flip = True,\n",
    "                                 flip_vert=True, \n",
    "                                 max_lighting=0.1, \n",
    "                                 max_zoom=1.05,\n",
    "                                 max_warp=0.,\n",
    "                                 max_rotate=15,\n",
    "                                 p_affine=0.75,\n",
    "                                 p_lighting=0.75\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this object is an encapsulation of our data it is a necessay step for the data to fit in a model under FASTAI\n",
    "pathofdata = \"/input/\"\n",
    "data  = ImageDataBunch.from_df(path=pathofdata, \n",
    "                               df=traindf, \n",
    "                               folder=\"images\",\n",
    "                               label_delim=None,\n",
    "                               valid_pct=0.2,\n",
    "                               seed=100,\n",
    "                               fn_col=0, \n",
    "                               label_col=1, \n",
    "                               suffix='',\n",
    "                               ds_tfms=transformations, \n",
    "                               size=512,\n",
    "                               bs=64, \n",
    "                               val_bs=32,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some images and their correspanding classes\n",
    "data.show_batch(rows=3, figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing is a necessay pre proccessing step to make the model generalize better on the data\n",
    "#it carries out a simple function on eacch image:subtract the mean of pixels and divide by the variance\n",
    "data = data.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####PHASE 2 :MODELING AND TRAINNING\n",
    "#our model in a CNN architecture specificly a resnet34 a commun architecture used in computer vision tasks \n",
    "learner = cnn_learner(data, \n",
    "                      models.resnet34, \n",
    "                      pretrained=True\n",
    "                      ,metrics=[error_rate, accuracy],).to_fp16()\n",
    "learner.model_dir = '/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we set the hyperparameter leraning rate to be 0.002 (a value signifying how much we should update the weights at each iteration)\n",
    "#after trying out a bunch of values \n",
    "#this value seems to work the best\n",
    "#also we set epochs to be 10 due to time constraint \n",
    "#epachs is how many times does the model go through the whole dataset\n",
    "lr = 0.002\n",
    "epochs=10\n",
    "#now we fit the resnet34 to our data \n",
    "#it takes about 50 minutes on kaggle (please activate GPU accelerator if running on kaggle)\n",
    "learner.fit_one_cycle(epochs, lr)\n",
    "#this saves the weights of the   model so that you can use it later on without trainning the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment these lines to load pretrained model \n",
    "learner.export()\n",
    "learner = load_learner(path=\"/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this shows a batch of the model predictions on the train dataset \n",
    "learner.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PHASE 3 RUNNING THE MODEL ON THE TEST DATASET \n",
    "#FIRST we import the test dataset\n",
    "testdf = pd.read_csv(\"/test.csv\")\n",
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets get the paths of all test dataset images\n",
    "pathofdata = \"/\"\n",
    "testdata= ImageList.from_folder(pathofdata+\"images\")\n",
    "testdata.filter_by_func(lambda x: x.name.startswith(\"Test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading an image and predict its  classe with our model\n",
    "img1 = open_image(testdata.items[0])\n",
    "learner.predict(img1)\n",
    "#--->the result is 3 which is the label of the scab desease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PHASE 4 PREPARING SUBMISSION FILE TO CHECK  OUR ACCURACY ON UNSEEN DATA \n",
    "#SUBMISSION DATAFRAME\n",
    "resultlist = []\n",
    "for item in testdata.items:\n",
    "    img = open_image(item)\n",
    "    predval = learner.predict(img)[2].tolist()\n",
    "    predval.insert(0,item.name[:-4:])\n",
    "    resultlist.append(predval)\n",
    "resultdf = pd.DataFrame(resultlist)\n",
    "resultdf.columns = sampsubmit.columns\n",
    "resultdf.set_index(\"image_id\",inplace=True)\n",
    "resultdf = resultdf.loc[sampsubmit.image_id,:]\n",
    "resultdf.reset_index(inplace=True)\n",
    "resultdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPARE SUBMISSION CSV YOU CAN FIND IT IN OUTPUT FOLDER ON THE RIGHT \n",
    "resultdf.to_csv(\"submit.csv\",index=False)\n",
    "#AFTER SUBMITING OUR RESULTS TO KAGGLE THE MODEL \n",
    "#PERFORMED OUTSTANDINGLY WELL SCORING 0.94405% OF ACCURACY ON UNSEEN TEST DATASET\n",
    "\n",
    "'''THANK YOU \n",
    "END OF THE KERNEL'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
